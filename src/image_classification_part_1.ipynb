{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Image Classification\n",
    "\n",
    "### What is Image Classification?\n",
    "\n",
    "Image classification is the process of determining what is shown in an image.\n",
    "\n",
    "[Silicon Valley - Hot Dog Not Hot Dog](https://www.youtube.com/watch?v=ACmydtFDTGs)\n",
    "\n",
    "We can use deep learning to do this for us. When classifying images using deep learning, we use a convolutional neural network (CNN). CNNs are specifically designed to process images. For this session, we will steer clear of the theory behind CNN's and focus on the practical stuff.\n",
    "\n",
    "![](../additional/img/cnn1.png)\n",
    "\n",
    "## How do CNNs learn to classify?\n",
    "\n",
    "First we need to decide what we want to teach our model.\n",
    "\n",
    "Do we want our model to correctly identify:\n",
    "\n",
    "* Cats and dogs?\n",
    "\n",
    "* Different types of cats?\n",
    "\n",
    "* Different types of dogs?\n",
    "\n",
    "* Different types of flowers?\n",
    "\n",
    "* Everything?\n",
    "\n",
    "CNNs work in a similar way as a human brain (inspired by the way the visual cortex works). If we, as humans, are exposed to something new, it takes time for us to learn what it is.\n",
    "\n",
    "### Can you identify this berry?\n",
    "\n",
    "![](../additional/img/Wild_red_baneberry_1.jpg)\n",
    "\n",
    "If our brain hasn't been exposed to to something, classification becomes a guessing game. This applies to deep learning as well.\n",
    "\n",
    "We need to teach our model what different berries look like.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We need to train our model what the difference is between the different classes.\n",
    "\n",
    "After training, when the model is faced with a new image that it hasn't seen before, it needs to decide for itself what is most likely shown in the image.\n",
    "\n",
    "![](../additional/img/cat_dog.png)\n",
    "\n",
    "![](../additional/img/cat_dog_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training / Retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained architechture & Transfer Learning\n",
    "\n",
    "**Architechture used**: [MobileNet](https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html) is a a small efficient convolutional neural network, which is designed to accomodate the restricted resources for an on-device or embedded application.\n",
    "\n",
    "The MobileNet is configurable in two ways:\n",
    "\n",
    "- Input image resolution: 128,160,192, or 224px. Unsurprisingly, feeding in a higher resolution image takes more processing time, but results in better classification accuracy.\n",
    "- The relative size of the model as a fraction of the largest MobileNet: 1.0, 0.75, 0.50, or 0.25.\n",
    "\n",
    "We will use 160 and 0.75 for the first run.\n",
    "```\n",
    "mobilenet_v1_075_160\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining script\n",
    "The retrain script is from the [TensorFlow Hub repo](https://github.com/tensorflow/hub/blob/master/examples/image_retraining/retrain.py), and we have included in the workshop repo.\n",
    "\n",
    "Before running the script, there are a few arguments worth mentioning:\n",
    "\n",
    "- **bottleneck_dir** : path to cache bottleneck layer values as files\n",
    "- **how_many_training_steps** : How many training steps to run before ending\n",
    "- **summaries_dir** : Where to save training summary logs for TensorBoard\n",
    "- **output_graph** : Where to save the trained graph\n",
    "- **output_labels** : path to save the trained graph's labels\n",
    "- **tfhub_module** : *url* of the model architecture to use from TensorFlow Hub  \n",
    "- **image_dir** : path to labeled images for training\n",
    "\n",
    "You can retrive the whole list of arguments using the following command.\n",
    "\n",
    "```bash\n",
    "python src/retrain.py -h\n",
    "```\n",
    "\n",
    "Let's run the training with the following commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python src/retrain.py \\\n",
    "    --bottleneck_dir=tf_files/bottlenecks \\\n",
    "    --image_dir tf_files/data/train \\\n",
    "    --tfhub_module https://tfhub.dev/google/imagenet/mobilenet_v1_075_160/feature_vector/1 \\\n",
    "    --how_many_training_steps 500 \\\n",
    "    --train_batch_size 25 \\\n",
    "    --summaries_dir tf_files/retrain_logs \\\n",
    "    --output_graph tf_files/output_graph.pb \\\n",
    "    --output_labels tf_files/output_labels.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it work? \n",
    "The above script downloads the pre-trained model, adds a new final layer, and trains that layer on the cat/dog photos we provided. It contains two main phases:\n",
    "1. Calculates and caches the bottleneck values for each image\n",
    "2. Actual training of the final layer which makes the classification\n",
    "\n",
    "The techinques that make the training possible is **Transfer Learning**.\n",
    "\n",
    "### Transfer Learning\n",
    "**Transfer learning** is a machine learning method where a model developed for a related task is reused as the starting point for a new model. It has the following benefits\n",
    "\n",
    "- Utilize the power of pre-trained model to extract features from images\n",
    "- Faster...\n",
    "- Less data & less resource (Google: 1000x computing power to replace ml expert)\n",
    "\n",
    "The image below summarize the process. (Image retrived from a talk at [Google Cloud Next '17](https://www.youtube.com/watch?v=EnFyneRScQ8&feature=youtu.be&t=4m17s) by *Yufeng Guo*)\n",
    "\n",
    "![](../additional/img/retrain.png)\n",
    "\n",
    "### Bottlenecks \n",
    "A **bottleneck** is an informal term we often use for the layer just before the final output layer that actually does the classification (TensorFlow Hub calls this an \"image feature vector\"). This penultimate layer has been trained to output a set of values that's good enough for the classifier to use to distinguish between all the classes it's been asked to recognize.\n",
    "\n",
    "Because every image is reused multiple times during training and calculating each bottleneck takes a significant amount of time, it speeds things up to cache these bottleneck values on disk so they don't have to be repeatedly recalculated. The command you ran saves these files to the `bottlenecks/` directory. If you rerun the script, they'll be reused, so you don't have to wait for this part again.\n",
    "\n",
    "### Actual training\n",
    "You'll see a series of step outputs, each one showing training accuracy, validation accuracy, and the cross entropy. \n",
    "- **training accuracy** : percent of the images used in the current training batch were labeled with the correct class. \n",
    "- **validation accuracy** : the precision on a randomly-selected group of images different from the training.\n",
    "    - **Overfitting** : model may overfit to the noise during training, so we use **validation accuracy** to measure the true performance. If the train accuracy is high but the validation accuracy remains low, that means the network is overfitting and remembering noise\n",
    "- **cross entropy** : a loss function which gives a glimpse into how well the learning process is progressing. It should keep going down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "### What is TensorBoard?\n",
    "\n",
    "TensorBoard is a suite of visualization tools. The goal of Tensorboard is to remove some of the complexity and confusion behind deep learning. TensorBoard can be used to:\n",
    "\n",
    "* visualize your Tensorflow graph\n",
    "* plot quantitative metrics about training and validation of your model\n",
    "\n",
    "### How do I access TensorBoard?\n",
    "\n",
    "Run the following following command in bash:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir src/tmp/retrain_logs`\n",
    "```\n",
    "\n",
    "Check out the last line. It should say something like:\n",
    "\n",
    "```bash \n",
    "TensorBoard 1.8.0 at http://jharmse:6006 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "This means that TensorBoard is available at `http://jharmse:6006`\n",
    "\n",
    "Type in your equivalent of `jharmse:6006` into your browser (Chrome, Firefox, etc.)\n",
    "\n",
    "You should now see TensorBoard.\n",
    "\n",
    "**Remember: Once you are done exploring Tensorboard, go to the place where you launched TensorBoard and press `CTRL+C` to quit TensorBoard. Otherwise it will keep on running in the background.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few interesting Tensorflow features\n",
    "\n",
    "### Scalars\n",
    "\n",
    "Here you can visualize any recording you decided to make during model training. Things you might be interested in visualizing are things like:\n",
    "\n",
    "* model accuracy across iterations\n",
    "* the cross entropy (certainty of model predictions) across iterations\n",
    "\n",
    "You can visualizations for different runs, like training and validation. This can help you gain a deeper understanding of the model's performance. For example, if a model's training accuracy is very high towards the end of the iterations, but the validation accuracy is low, it means that the model has started memorizing the training data instead of simply learning the features of the images.\n",
    "\n",
    "### Graphs\n",
    "\n",
    "Here you can visually inspect your neural network. For the purposes of this workshop we aren't going to go into the details of this.\n",
    "\n",
    "### Histograms\n",
    "\n",
    "On the histogram tab you can visualize tensors (or values within the graph) across time.\n",
    "\n",
    "This is really cool since you can see how the parameters change across time to best fit the data it is training on.\n",
    "\n",
    "In our example, where we have two classes, we can see how our distributions become bimodal across iterations. This means that the values it is producing in an attempt to identify whether an image is a cat or dog starts starts to form two peaks. These peaks relate to our two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions using Trained Model\n",
    "\n",
    "**Responsible Person: Akshi**\n",
    "\n",
    "**Estimated Duration: 15 mins**\n",
    "\n",
    "#### Notes\n",
    "\n",
    "* Use ~3 image examples (2 good, 1 ambiguous)\n",
    "\n",
    "* Talk about interpreting the class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jharmse/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog 0.99786466\n",
      "cat 0.0021352973\n"
     ]
    }
   ],
   "source": [
    "%run -i label_image.py --image ../tf_files/data/test/4.jpg \\\n",
    "    --graph tmp/output_graph.pb \\\n",
    "    --labels tmp/output_labels.txt \\\n",
    "    --input_height 160 \\\n",
    "    --input_width 160 \\\n",
    "    --input_layer Placeholder \\\n",
    "    --output_layer final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning (Optional)\n",
    "\n",
    "**Responsible Person: Xinbin**\n",
    "\n",
    "**Estimated Duration: TBD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Different Image Dataset (Optional)\n",
    "\n",
    "**Responsible Person: Akshi**\n",
    "\n",
    "**Estimated Duration: TBD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Coding Challenge\n",
    "\n",
    "The School of AI is hands-on! We want everyone to try the things we are learning out for themselves to become more comfortable with the world of AI. We want to create coding challenges to motivate everyone to get their hands dirty with these concepts.\n",
    "\n",
    "#### This week's Challenge\n",
    "\n",
    "Use the concepts we learnt today to build your own image classifier! In other words, a model that learns images of your own choice!\n",
    "\n",
    "Submit the application on your own Github profile and share the link on the `Vancouver School of AI` Facebook page. The deadline is Monday, 17 September. We will then decide on the most interesting model which does a good job as classifying (you can use TensorBoard to explore how good of a job your model is doing).\n",
    "\n",
    "We will announce the winner on 18 September and make your model known to the world!\n",
    "\n",
    "### Next meetup\n",
    "\n",
    "Next time we will go into more depth about how image classifiers work - the theory behind the models! This will help you understand and improve your model by applying your own understanding! We will attempt to keep the theory as interesting as poosible!\n",
    "\n",
    "See you next time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
